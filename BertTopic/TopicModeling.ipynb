{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# BERTopic + llama-cpp-python\n",
    "%CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\n",
    "%pip install bertopic datasets\n",
    "\n",
    "# DataMapPlot\n",
    "%git clone https://github.com/TutteInstitute/datamapplot.git\n",
    "%pip install datamapplot/.\n",
    "\n",
    "# GPU-accelerated HDBSCAN + UMAP\n",
    "%pip install cudf-cu12 dask-cudf-cu12 --extra-index-url=https://pypi.nvidia.com\n",
    "%pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com\n",
    "%pip install cugraph-cu12 --extra-index-url=https://pypi.nvidia.com\n",
    "%pip install cupy-cuda12x -f https://pip.cupy.dev/aarch64\n",
    "\n",
    "%wget https://huggingface.co/TheBloke/OpenHermes-2.5-Mistral-7B-GGUF/resolve/main/openhermes-2.5-mistral-7b.Q4_K_M.gguf\n",
    "# !wget https://huggingface.co/TheBloke/dolphin-2.7-mixtral-8x7b-GGUF/resolve/main/dolphin-2.7-mixtral-8x7b.Q3_K_M.gguf\n",
    "\n",
    "%cd ../src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.Upload import dowload_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Use llama.cpp to load in a Quantized LLM\n",
    "llm = Llama(model_path=\"openhermes-2.5-mistral-7b.Q4_K_M.gguf\", n_gpu_layers=-1, n_ctx=4096, stop=[\"Q:\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired, LlamaCPP\n",
    "\n",
    "prompt = \"\"\" Q:\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the above information, can you give a short label of the topic of at most 5 words?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "representation_model = {\n",
    "    \"KeyBERT\": KeyBERTInspired(),\n",
    "    \"LLM\": LlamaCPP(llm, prompt=prompt),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import HDBSCAN\n",
    "# from umap import UMAP\n",
    "# from hdbscan import HDBSCAN\n",
    "\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"BAAI/bge-small-en\")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "# Pre-reduce embeddings for visualization purposes\n",
    "reduced_embeddings = UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sub-models\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=400, metric='euclidean', cluster_selection_method='eom', prediction_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(\n",
    "\n",
    "  # Sub-models\n",
    "  embedding_model=embedding_model,\n",
    "  umap_model=umap_model,\n",
    "  hdbscan_model=hdbscan_model,\n",
    "  representation_model=representation_model,\n",
    "\n",
    "  # Hyperparameters\n",
    "  top_n_words=10,\n",
    "  verbose=True\n",
    ")\n",
    "\n",
    "# Train model\n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamapplot\n",
    "import re\n",
    "\n",
    "# Create a label for each document\n",
    "llm_labels = [re.sub(r'\\W+', ' ', label[0][0].split(\"\\n\")[0].replace('\"', '')) for label in topic_model.get_topics(full=True)[\"LLM\"].values()]\n",
    "llm_labels = [label if label else \"Unlabelled\" for label in llm_labels]\n",
    "all_labels = [llm_labels[topic+topic_model._outliers] if topic != -1 else \"Unlabelled\" for topic in topics]\n",
    "\n",
    "# Run the visualization\n",
    "datamapplot.create_plot(\n",
    "    reduced_embeddings,\n",
    "    all_labels,\n",
    "    label_font_size=11,\n",
    "    title=\"ArXiv - BERTopic\",\n",
    "    sub_title=\"Topics labeled with `openhermes-2.5-mistral-7b`\",\n",
    "    label_wrap_width=20,\n",
    "    use_medoids=True,\n",
    "    logo_width=0.16\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
